{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ktTpk9bCr_Lg"},"source":["# **PyTorch Basics Tutorial**\n","\n","The following tutorial is adapted from the [DeepLearningForNLPInPytorch tutorial](https://github.com/rguthrie3/DeepLearningForNLPInPytorch/blob/master/Deep%20Learning%20for%20Natural%20Language%20Processing%20with%20Pytorch.ipynb) and the [Official PyTorch tutorials](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py)."]},{"cell_type":"markdown","metadata":{"id":"gT-s9_PdslEW"},"source":["## Installation\n","\n","**Via Anaconda/Miniconda:**  \n","`condainstall pytorch-c pytorch`\n","\n","**Via pip:**  \n","`pip3 install torch`\n"]},{"cell_type":"code","metadata":{"id":"GlRjjJqDr5bs","outputId":"d6014db2-258f-4123-be80-d2f16812ec29","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329534282,"user_tz":-420,"elapsed":9058,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["import torch\n","print(torch.__version__)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.5.1+cu121\n"]}]},{"cell_type":"markdown","metadata":{"id":"xaso_dtjsExr"},"source":["## 1. Tensors\n","Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n","\n","### 1.1 Creating Tensors from data\n","Tensors can be created from Python lists with the `torch.Tensor()` function."]},{"cell_type":"code","metadata":{"id":"zpQ5Oek2s4ca","outputId":"1f0e95fa-8933-4a54-d8f1-0662bf466c89","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329543771,"user_tz":-420,"elapsed":138,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Example with 1-D data\n","data = [1.0, 2.0, 3.0]\n","tensor = torch.Tensor(data)\n","print(\"Example with 1-D data\")\n","print(tensor)\n","\n","# Example with 2-D data\n","data = [[1., 2., 3.], [4., 5., 6]]\n","tensor = torch.Tensor(data)\n","print(\"\\nExample with 2-D data\")\n","print(tensor)\n","\n","# Example with 3-D data\n","data = [[[1.,2.], [3.,4.]],\n","        [[5.,6.], [7.,8.]]]\n","tensor = torch.Tensor(data)\n","print(\"\\nExample with 3-D data\")\n","print(tensor)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Example with 1-D data\n","tensor([1., 2., 3.])\n","\n","Example with 2-D data\n","tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","\n","Example with 3-D data\n","tensor([[[1., 2.],\n","         [3., 4.]],\n","\n","        [[5., 6.],\n","         [7., 8.]]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"b18oELGNvhNg"},"source":["### 1.2 Initializing an empty Tensor\n","An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\n"]},{"cell_type":"code","metadata":{"id":"kg_gi1AWv_1E","outputId":"8cd6460a-4638-4896-d921-862498628f57","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329563498,"user_tz":-420,"elapsed":24,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Construct a 2x3 matrix, uninitialized\n","x = torch.empty(2, 3)\n","print(x)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[2.6698e+03, 4.3496e-41, 1.4691e-33],\n","        [0.0000e+00, 5.6757e+17, 4.3495e-41]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"gDr4ZzQrwOmZ"},"source":["### 1.3 Randomly initialized Tensor\n","\n"]},{"cell_type":"code","metadata":{"id":"r0pZQfUywgwL","outputId":"038eff12-1249-4487-a030-6faa3f1454be","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329571471,"user_tz":-420,"elapsed":17,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["x = torch.rand(2, 3)\n","print(x)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.6784, 0.6311, 0.4350],\n","        [0.7773, 0.2104, 0.0717]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"rLJOlS32wjFg"},"source":["### 1.4 Tensor with zeros or ones"]},{"cell_type":"code","metadata":{"id":"JQ0JM9njwtFr","outputId":"aa4f340a-e70a-42a3-e515-cfadf75be7aa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329575220,"user_tz":-420,"elapsed":16,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Create a matrix of all zeros\n","x = torch.zeros(2, 3)\n","print(\"Matrix of zeros\")\n","print(x)\n","\n","# Create a matrix of all zeros and explicitly set data type to be long int\n","x = torch.zeros(2, 3, dtype=torch.long)\n","print(\"\\nMatrix of zeros typecasted to long\")\n","print(x)\n","\n","x = torch.ones(2, 3, dtype=torch.long)\n","print(\"\\nMatrix of ones typecasted to long\")\n","print(x)\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Matrix of zeros\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","\n","Matrix of zeros typecasted to long\n","tensor([[0, 0, 0],\n","        [0, 0, 0]])\n","\n","Matrix of ones typecasted to long\n","tensor([[1, 1, 1],\n","        [1, 1, 1]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"s0HQKRy2wsDd"},"source":["### 1.5 Create Tensor based on existing Tensor"]},{"cell_type":"code","metadata":{"id":"visdOehpxqd-","outputId":"7e4f2b36-2d36-43d1-ce29-6dec5f14ec81","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741319578817,"user_tz":-420,"elapsed":12,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n","print(x)\n","\n","x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n","print(x)                                      # result has the same size"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n","tensor([[-0.6471, -0.3010, -0.1339],\n","        [ 0.4698, -1.6798,  0.3745]])\n"]}]},{"cell_type":"markdown","metadata":{"id":"HLZfCcObzBTe"},"source":["### 1.6 Size of a Tensor\n","`torch.Size` is in fact a tuple, so it supports all tuple operations."]},{"cell_type":"code","metadata":{"id":"YVIu-uZnzEm-","outputId":"f4ab8799-8bba-420d-8bdf-3b4f20d47578","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329588619,"user_tz":-420,"elapsed":16,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Example with 1-D data\n","data = [1.0, 2.0, 3.0]\n","tensor = torch.Tensor(data)\n","print(\"Example with 1-D data\")\n","print(tensor)\n","print(tensor.shape)\n","\n","# Example with 2-D data\n","data = [[1., 2., 3.], [4., 5., 6]]\n","tensor = torch.Tensor(data)\n","print(\"\\nExample with 2-D data\")\n","print(tensor)\n","print(tensor.shape)\n","\n","# Example with 3-D data\n","data = [[[1.,2.], [3.,4.]],\n","        [[5.,6.], [7.,8.]]]\n","tensor = torch.Tensor(data)\n","print(\"\\nExample with 3-D data\")\n","print(tensor)\n","print(tensor.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Example with 1-D data\n","tensor([1., 2., 3.])\n","torch.Size([3])\n","\n","Example with 2-D data\n","tensor([[1., 2., 3.],\n","        [4., 5., 6.]])\n","torch.Size([2, 3])\n","\n","Example with 3-D data\n","tensor([[[1., 2.],\n","         [3., 4.]],\n","\n","        [[5., 6.],\n","         [7., 8.]]])\n","torch.Size([2, 2, 2])\n"]}]},{"cell_type":"markdown","metadata":{"id":"cYai6C6H0kKx"},"source":["### 1.7 Operations with Tensors\n","Most operations are very similar to NumPy."]},{"cell_type":"code","metadata":{"id":"ZRj42hPO0prW","outputId":"3df71529-fb0a-421d-e2fa-17c812bdb940","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329607233,"user_tz":-420,"elapsed":29,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Addition\n","x = torch.Tensor([ 1., 2., 3. ])\n","y = torch.Tensor([ 4., 5., 6. ])\n","\n","# using arithmetic operation\n","z = x + y\n","print(z)\n","\n","# using method\n","print(torch.add(x, y))\n","\n","# using method and providing an output tensor as argument\n","output = torch.empty(2, 3)\n","torch.add(x, y, out=output)\n","print(output)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([5., 7., 9.])\n","tensor([5., 7., 9.])\n","tensor([5., 7., 9.])\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-38954958df63>:14: UserWarning: An output with one or more elements was resized since it had shape [2, 3], which does not match the required output shape [3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n","  torch.add(x, y, out=output)\n"]}]},{"cell_type":"code","metadata":{"id":"cjy0Zqik0-wL","outputId":"ac0d3fd4-0b61-44ee-9526-6cd15afa1587","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329616190,"user_tz":-420,"elapsed":50,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# In-place addition\n","\n","x = torch.Tensor([ 1., 2., 3. ])\n","y = torch.Tensor([ 4., 5., 6. ])\n","\n","y.add_(x)\n","print(y)"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([5., 7., 9.])\n"]}]},{"cell_type":"markdown","metadata":{"id":"hFetPkbO1750"},"source":["Any operation that mutates a tensor in-place is post-fixed with an underscore `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`.\n","\n","See [the PyTorch official documentation](http://pytorch.org/docs/torch.html) for a complete list of the massive number of operations available to you.  They expand beyond just mathematical operations.\n"]},{"cell_type":"code","metadata":{"id":"gedfbDbd06Fn","outputId":"138ba279-8464-45bb-c95b-0f02298f691f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329627852,"user_tz":-420,"elapsed":20,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Indexing\n","\n","x = torch.Tensor([[1., 2., 3.], [4., 5., 6]])\n","print(x[:, 1]) # Gets column with index 1"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([2., 5.])\n"]}]},{"cell_type":"markdown","metadata":{"id":"_IqeYxdg3Bvk"},"source":["### 1.8 Reshaping Tensors"]},{"cell_type":"code","metadata":{"id":"pUwsXsfw26g_","outputId":"a7446135-a310-40b4-b286-a59d0114f254","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329631773,"user_tz":-420,"elapsed":8,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(x.size(), y.size(), z.size())"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"]}]},{"cell_type":"code","metadata":{"id":"clJzuzI93U7k","outputId":"10749e0d-6341-4cca-a298-b422eae69ec2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741319754346,"user_tz":-420,"elapsed":137,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.0208])\n","-0.020768431946635246\n"]}]},{"cell_type":"markdown","metadata":{"id":"zRbkdZcArlk7"},"source":["### 1.9 Converting to and from NumPy\n","Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n","\n","The Torch Tensor and NumPy array will **share their underlying memory locations** (if the Torch Tensor is on CPU), and **changing one will change the other**.\n","\n"]},{"cell_type":"code","metadata":{"id":"BlLtucZM3g-N","outputId":"2177382c-6d58-4535-abec-a5888c1ffdc7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329655458,"user_tz":-420,"elapsed":58,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["a = torch.ones(5)\n","print(\"Original a:\", a)\n","\n","b = a.numpy()\n","print(\"Original b:\", b)\n","\n","a.add_(1)\n","print(\"New a:\", a)\n","print(\"New b:\", b)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Original a: tensor([1., 1., 1., 1., 1.])\n","Original b: [1. 1. 1. 1. 1.]\n","New a: tensor([2., 2., 2., 2., 2.])\n","New b: [2. 2. 2. 2. 2.]\n"]}]},{"cell_type":"code","metadata":{"id":"Cij37AWq31XG","outputId":"e1abb583-8098-4655-c630-e15bd8b5b086","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329676082,"user_tz":-420,"elapsed":22,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a)\n","print(a)\n","print(b)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"g-T79NfE4Ck2"},"source":["### 1.10. CUDA Tensors\n","\n","Tensors can be moved onto any device using the `.to` method.\n"]},{"cell_type":"markdown","metadata":{"id":"kbUIutU44psf"},"source":["### Enable GPU on your Colab notebook\n","\n","Go to Edit -> Notebook Settings -> select GPU as Hardware accelerator\n","\n","<img src=\"https://jovianlin.io/content/images/2018/01/Screen-Shot-2018-01-23-at-8.38.04-AM.png\" width=\"300\">"]},{"cell_type":"code","metadata":{"id":"KWaJxd1-4M2w","outputId":"cf14b227-9fde-4f7f-b611-c2a27ab87dc6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329691502,"user_tz":-420,"elapsed":646,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["# Try to run this cell with both GPU support and without\n","import torch\n","print(\"CUDA available?\", torch.cuda.is_available())\n","\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    x = torch.Tensor([1.0, 2.0, 3.0])\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA available? True\n","tensor([2., 3., 4.], device='cuda:0')\n","tensor([2., 3., 4.], dtype=torch.float64)\n"]}]},{"cell_type":"markdown","metadata":{"id":"UqClHzpw6Lg3"},"source":["## 2. Autograd: Automatic Differentiation\n","\n","The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n","\n","``torch.Tensor`` is the central class of the package. If you set its attribute\n","``.requires_grad`` as ``True``, it **starts to track all operations on it**. When\n","you finish your computation you can call ``.backward()`` and have **all the\n","gradients computed automatically**. The gradient for this tensor will be\n","accumulated into ``.grad`` attribute.\n","\n","To **stop a tensor from tracking history**, you can call ``.detach()`` to detach\n","it from the computation history, and to prevent future computation from being\n","tracked.\n","\n","To **prevent tracking history (and using memory)**, you can also wrap the code block\n","in ``with torch.no_grad():``. This can be particularly helpful when evaluating a\n","model because the model may have trainable parameters with `requires_grad=True`,\n","but for which we don't need the gradients."]},{"cell_type":"code","metadata":{"id":"s3JXX8xr8HWJ","outputId":"a22c38db-d009-49a3-bf24-2e8aa857bccc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329757076,"user_tz":-420,"elapsed":15,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["import torch\n","x = torch.ones(2, 2, requires_grad=True)\n","print(x)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)\n"]}]},{"cell_type":"code","metadata":{"id":"CuHGuSWn8Pfm","outputId":"3a913a73-74f7-47ff-d8df-1c33653ed5e4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329757510,"user_tz":-420,"elapsed":8,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["y = x + 2\n","print(y)\n","\n","# y was created as a result of an operation, so it has a grad_fn."],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","metadata":{"id":"ylMfa4AP8ZfW","outputId":"fcf2974f-b250-4092-ae69-5612dbcf82c8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329758393,"user_tz":-420,"elapsed":17,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["z = y * y * 3\n","out = z.mean()\n","\n","print(z, out)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[27., 27.],\n","        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"TbbCf8kM8-hd"},"source":["``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n","flag in-place. The input flag defaults to ``False`` if not given.\n","\n"]},{"cell_type":"code","metadata":{"id":"TbbdshuP-mRz","outputId":"694504e0-11a8-4cdf-bdb7-2a759b417df5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329787768,"user_tz":-420,"elapsed":17,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["x = torch.tensor(2.0, requires_grad=True)\n","y = x**2 + 3*x + 1\n","print(y)\n","y.backward()\n","\n","print(x.grad)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(11., grad_fn=<AddBackward0>)\n","tensor(7.)\n"]}]},{"cell_type":"markdown","metadata":{"id":"nk1g2FU8YwfS"},"source":["You can also stop autograd from tracking history on Tensors with `.requires_grad=True` either by wrapping the code block in with `torch.no_grad()`:"]},{"cell_type":"code","metadata":{"outputId":"561e1dc9-c83e-4bf3-9f27-7c92335e60bb","id":"h-tRLTbhYtWL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741329818698,"user_tz":-420,"elapsed":20,"user":{"displayName":"Trí Lê Đức","userId":"07422449082197278686"}}},"source":["print(x.requires_grad)\n","print((x ** 2).requires_grad)\n","\n","with torch.no_grad():\n","    print((x ** 2).requires_grad)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["True\n","True\n","False\n"]}]},{"cell_type":"markdown","metadata":{"id":"V5716VvqZjfV"},"source":["Every time a variable is back propogated through, the gradient will be accumulated instead of being replaced. Calling `tensor.grad_zero()` would reset the gradients that have accumulated to 0.\n"]},{"cell_type":"markdown","metadata":{"id":"LvVKKkOHaAu0"},"source":[]}]}